Spam Classifier Project - Procedure Explanation
===============================================

1. Dataset Preparation
---------------------
- Downloaded the SpamAssassin public datasets containing spam, easy_ham, and hard_ham emails.
- Extracted the datasets and organized them into category folders.
- Used a Python script to split each category into training (80%) and test (20%) sets, creating 'train' and 'test' subfolders for each.

2. Data Loading and Exploration
------------------------------
- In the Jupyter notebook, defined the paths to the train and test folders for each category.
- Listed a few files from each folder to verify the split.

3. Data Preprocessing and Feature Extraction
--------------------------------------------
- Defined a preprocessing pipeline to:
  - Optionally remove email headers.
  - Convert text to lowercase.
  - Remove punctuation.
  - Replace URLs with 'URL' and numbers with 'NUMBER'.
- Built a vocabulary from the training set (all unique words).
- Converted each email into a feature vector:
  - By default, used binary features (1 if a word is present, 0 if absent).
  - Optionally, can use word counts instead.
- Assigned labels: spam = 1, ham (easy_ham and hard_ham) = 0.

4. Model Training
-----------------
- Used the Multinomial Naive Bayes classifier from scikit-learn.
- Trained the model on the training feature vectors and labels.

5. Model Evaluation
-------------------
- Predicted labels for the test set.
- Evaluated the model using:
  - Accuracy
  - Precision
  - Recall
  - F1-score
  - Confusion matrix
  - Classification report

6. Customization and Experimentation
------------------------------------
- The notebook allows you to:
  - Change preprocessing options (e.g., enable stemming, use counts instead of binary features).
  - Try different classifiers (e.g., Logistic Regression, SVM).
  - Analyze misclassified emails for further improvements.

Summary
-------
This workflow guides you from raw email data to a working spam classifier, with clear steps for data preparation, feature extraction, model training, and evaluation. You can experiment with different preprocessing and modeling choices to optimize your classifier's performance.
